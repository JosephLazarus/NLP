{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains notes and Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 1\n",
    "\n",
    "1.\tInstall Python (if you don’t have it already) and install NLTK.  \n",
    "\n",
    "2.\tFollow the instructions in chapter 1 of Bird-Klein for implementing a “lexical diversity” scoring routine.\n",
    "\n",
    "3.\tGo to http://www.gutenberg.org/ebooks/bookshelf/215  and select texts of different grade levels (e.g., fourth reader, fifth reader et al)\n",
    "Report the lexical diversity score of each. Explain whether the result was surprising.\n",
    "\n",
    "4.\tAlso compare the vocabulary size of the same three texts. Explain whether the result was surprising.  \n",
    "\n",
    "5.\tWrite a paragraph arguing whether vocabulary size and lexical diversity in combination could be a better measure of text difficulty (or reading level) than either measure is by itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jump to Homework\n",
    "\n",
    "<a href=\"#hmw\">Homework : </a> use this embedded link to skip notes and go right to the homework. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes from Text Book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going further you should install NLTK 3.0, downloadable for free from http://nltk.org/. Follow the instructions there to download the version required for your platform.\n",
    "\n",
    "Once you've installed NLTK, start up the Python interpreter as before, and install the data required for the book by typing the following two commands at the Python prompt, then selecting the book collection as shown in 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is downloaded to your machine, you can load some of it using the Python interpreter. The first step is to type a special command at the Python prompt which tells the interpreter to load some texts for us to explore: from nltk.book import *. This says \"from NLTK's book module, load all items.\" The book module contains all the data you will need as you read this chapter. After printing a welcome message, it loads the text of several books (this will take a few seconds). Here's the command again, together with the output that you will see. Take care to get spelling and punctuation right, and remember that you don't type the >>>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3   Searching Text\n",
    "There are many ways to examine the context of a text apart from simply reading it. A concordance view shows us every occurrence of a given word, together with some context. Here we look up the word monstrous in Moby Dick by entering text1 followed by a period, then the term concordance, and then placing \"monstrous\" in parentheses:\n",
    "\n",
    "\n",
    "The first time you use a concordance on a particular text, it takes a few extra seconds to build an index so that subsequent searches are fast.\n",
    "\n",
    "Once you've spent a little while examining these texts, we hope you have a new sense of the richness and diversity of language. In the next chapter you will learn how to access a broader range of text, including text in languages other than English.\n",
    "\n",
    "A concordance permits us to see words in context. For example, we saw that monstrous occurred in contexts such as the ___ pictures and a ___ size . What other words appear in a similar range of contexts? We can find out by appending the term similar to the name of the text in question, then inserting the relevant word in parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(text1.similar(\"monstrous\"))\n",
    "#text1: Moby Dick by Herman Melville 1851\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Text: Moby Dick by Herman Melville 1851>'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very so exceedingly heartily a as good great extremely remarkably\n",
      "sweet vast amazingly\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(text2.similar(\"monstrous\"))\n",
    "#text2: Sense and Sensibility by Jane Austen 1811"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term common_contexts allows us to examine just the contexts that are shared by two or more words, such as monstrous and very. We have to enclose these words by square brackets as well as parentheses, and separate them with a comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_pretty am_glad a_lucky is_pretty be_glad\n"
     ]
    }
   ],
   "source": [
    "text2.common_contexts([\"monstrous\", \"very\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context. However, we can also determine the location of a word in the text: how many words from the beginning it appears. This positional information can be displayed using a dispersion plot. Each stripe represents an instance of a word, and each row represents the entire text. In 1.2 we see some striking patterns of word usage over the last 220 years (in an artificial text constructed by joining the texts of the Inaugural Address Corpus end-to-end). You can produce this plot as shown below. You might like to try more words (e.g., liberty, constitution), and different texts. Can you predict the dispersion of a word before you view it? As before, take care to get the quotes, commas, brackets and parentheses exactly right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building ngram index...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laid by her , and said unto Cain , Where art thou , and said , Go to ,\n",
      "I will not do it for ten ' s sons ; we dreamed each man according to\n",
      "their generatio the firstborn said unto Laban , Because I said , Nay ,\n",
      "but Sarah shall her name be . , duke Elah , duke Shobal , and Akan .\n",
      "and looked upon my affliction . Bashemath Ishmael ' s blood , but Isra\n",
      "for as a prince hast thou found of all the cattle in the valley , and\n",
      "the wo The\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"laid by her , and said unto Cain , Where art thou , and said , Go to ,\\nI will not do it for ten ' s sons ; we dreamed each man according to\\ntheir generatio the firstborn said unto Laban , Because I said , Nay ,\\nbut Sarah shall her name be . , duke Elah , duke Shobal , and Akan .\\nand looked upon my affliction . Bashemath Ishmael ' s blood , but Isra\\nfor as a prince hast thou found of all the cattle in the valley , and\\nthe wo The\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4   Counting Vocabulary**<br />\n",
    "The most obvious fact about texts that emerges from the preceding examples is that they differ in the vocabulary they use. In this section we will see how to use the computer to count the words in a text in a variety of useful ways. As before, you will jump right in and experiment with the Python interpreter, even though you may not have studied Python systematically yet. Test your understanding by modifying the examples, and trying the exercises at the end of the chapter.\n",
    "\n",
    "Let's begin by finding out the length of a text from start to finish, in terms of the words and punctuation symbols that appear. We use the term len to get the length of something, which we'll apply here to the book of Genesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44764"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Genesis has 44,764 words and punctuation symbols, or \"tokens.\" A token is the technical name for a sequence of characters — such as hairy, his, or :) — that we want to treat as a group. When we count the number of tokens in a text, say, the phrase to be or not to be, we are counting occurrences of these sequences. Thus, in our example phrase there are two occurrences of to, two of be, and one each of or and not. But there are only four distinct vocabulary items in this phrase. How many distinct words does the book of Genesis contain? To work this out in Python, we have to pose the question slightly differently. The vocabulary of a text is just the set of tokens that it uses, since in a set, all duplicates are collapsed together. In Python we can obtain the vocabulary items of text3 with the command: set(text3). When you do this, many screens of words will fly past. Now try the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ',)',\n",
       " '.',\n",
       " '.)',\n",
       " ':',\n",
       " ';',\n",
       " ';)',\n",
       " '?',\n",
       " '?)',\n",
       " 'A',\n",
       " 'Abel',\n",
       " 'Abelmizraim',\n",
       " 'Abidah',\n",
       " 'Abide',\n",
       " 'Abimael',\n",
       " 'Abimelech',\n",
       " 'Abr',\n",
       " 'Abrah',\n",
       " 'Abraham',\n",
       " 'Abram',\n",
       " 'Accad',\n",
       " 'Achbor',\n",
       " 'Adah',\n",
       " 'Adam',\n",
       " 'Adbeel',\n",
       " 'Admah',\n",
       " 'Adullamite',\n",
       " 'After',\n",
       " 'Aholibamah',\n",
       " 'Ahuzzath',\n",
       " 'Ajah',\n",
       " 'Akan',\n",
       " 'All',\n",
       " 'Allonbachuth',\n",
       " 'Almighty',\n",
       " 'Almodad',\n",
       " 'Also',\n",
       " 'Alvah',\n",
       " 'Alvan',\n",
       " 'Am',\n",
       " 'Amal',\n",
       " 'Amalek',\n",
       " 'Amalekites',\n",
       " 'Ammon',\n",
       " 'Amorite',\n",
       " 'Amorites',\n",
       " 'Amraphel',\n",
       " 'An',\n",
       " 'Anah',\n",
       " 'Anamim',\n",
       " 'And',\n",
       " 'Aner',\n",
       " 'Angel',\n",
       " 'Appoint',\n",
       " 'Aram',\n",
       " 'Aran',\n",
       " 'Ararat',\n",
       " 'Arbah',\n",
       " 'Ard',\n",
       " 'Are',\n",
       " 'Areli',\n",
       " 'Arioch',\n",
       " 'Arise',\n",
       " 'Arkite',\n",
       " 'Arodi',\n",
       " 'Arphaxad',\n",
       " 'Art',\n",
       " 'Arvadite',\n",
       " 'As',\n",
       " 'Asenath',\n",
       " 'Ashbel',\n",
       " 'Asher',\n",
       " 'Ashkenaz',\n",
       " 'Ashteroth',\n",
       " 'Ask',\n",
       " 'Asshur',\n",
       " 'Asshurim',\n",
       " 'Assyr',\n",
       " 'Assyria',\n",
       " 'At',\n",
       " 'Atad',\n",
       " 'Avith',\n",
       " 'Baalhanan',\n",
       " 'Babel',\n",
       " 'Bashemath',\n",
       " 'Be',\n",
       " 'Because',\n",
       " 'Becher',\n",
       " 'Bedad',\n",
       " 'Beeri',\n",
       " 'Beerlahairoi',\n",
       " 'Beersheba',\n",
       " 'Behold',\n",
       " 'Bela',\n",
       " 'Belah',\n",
       " 'Benam',\n",
       " 'Benjamin',\n",
       " 'Beno',\n",
       " 'Beor',\n",
       " 'Bera',\n",
       " 'Bered',\n",
       " 'Beriah',\n",
       " 'Bethel',\n",
       " 'Bethlehem',\n",
       " 'Bethuel',\n",
       " 'Beware',\n",
       " 'Bilhah',\n",
       " 'Bilhan',\n",
       " 'Binding',\n",
       " 'Birsha',\n",
       " 'Bless',\n",
       " 'Blessed',\n",
       " 'Both',\n",
       " 'Bow',\n",
       " 'Bozrah',\n",
       " 'Bring',\n",
       " 'But',\n",
       " 'Buz',\n",
       " 'By',\n",
       " 'Cain',\n",
       " 'Cainan',\n",
       " 'Calah',\n",
       " 'Calneh',\n",
       " 'Can',\n",
       " 'Cana',\n",
       " 'Canaan',\n",
       " 'Canaanite',\n",
       " 'Canaanites',\n",
       " 'Canaanitish',\n",
       " 'Caphtorim',\n",
       " 'Carmi',\n",
       " 'Casluhim',\n",
       " 'Cast',\n",
       " 'Cause',\n",
       " 'Chaldees',\n",
       " 'Chedorlaomer',\n",
       " 'Cheran',\n",
       " 'Cherubims',\n",
       " 'Chesed',\n",
       " 'Chezib',\n",
       " 'Come',\n",
       " 'Cursed',\n",
       " 'Cush',\n",
       " 'Damascus',\n",
       " 'Dan',\n",
       " 'Day',\n",
       " 'Deborah',\n",
       " 'Dedan',\n",
       " 'Deliver',\n",
       " 'Diklah',\n",
       " 'Din',\n",
       " 'Dinah',\n",
       " 'Dinhabah',\n",
       " 'Discern',\n",
       " 'Dishan',\n",
       " 'Dishon',\n",
       " 'Do',\n",
       " 'Dodanim',\n",
       " 'Dothan',\n",
       " 'Drink',\n",
       " 'Duke',\n",
       " 'Dumah',\n",
       " 'Earth',\n",
       " 'Ebal',\n",
       " 'Eber',\n",
       " 'Edar',\n",
       " 'Eden',\n",
       " 'Edom',\n",
       " 'Edomites',\n",
       " 'Egy',\n",
       " 'Egypt',\n",
       " 'Egyptia',\n",
       " 'Egyptian',\n",
       " 'Egyptians',\n",
       " 'Ehi',\n",
       " 'Elah',\n",
       " 'Elam',\n",
       " 'Elbethel',\n",
       " 'Eldaah',\n",
       " 'EleloheIsrael',\n",
       " 'Eliezer',\n",
       " 'Eliphaz',\n",
       " 'Elishah',\n",
       " 'Ellasar',\n",
       " 'Elon',\n",
       " 'Elparan',\n",
       " 'Emins',\n",
       " 'En',\n",
       " 'Enmishpat',\n",
       " 'Eno',\n",
       " 'Enoch',\n",
       " 'Enos',\n",
       " 'Ephah',\n",
       " 'Epher',\n",
       " 'Ephra',\n",
       " 'Ephraim',\n",
       " 'Ephrath',\n",
       " 'Ephron',\n",
       " 'Er',\n",
       " 'Erech',\n",
       " 'Eri',\n",
       " 'Es',\n",
       " 'Esau',\n",
       " 'Escape',\n",
       " 'Esek',\n",
       " 'Eshban',\n",
       " 'Eshcol',\n",
       " 'Ethiopia',\n",
       " 'Euphrat',\n",
       " 'Euphrates',\n",
       " 'Eve',\n",
       " 'Even',\n",
       " 'Every',\n",
       " 'Except',\n",
       " 'Ezbon',\n",
       " 'Ezer',\n",
       " 'Fear',\n",
       " 'Feed',\n",
       " 'Fifteen',\n",
       " 'Fill',\n",
       " 'For',\n",
       " 'Forasmuch',\n",
       " 'Forgive',\n",
       " 'From',\n",
       " 'Fulfil',\n",
       " 'G',\n",
       " 'Gad',\n",
       " 'Gaham',\n",
       " 'Galeed',\n",
       " 'Gatam',\n",
       " 'Gather',\n",
       " 'Gaza',\n",
       " 'Gentiles',\n",
       " 'Gera',\n",
       " 'Gerar',\n",
       " 'Gershon',\n",
       " 'Get',\n",
       " 'Gether',\n",
       " 'Gihon',\n",
       " 'Gilead',\n",
       " 'Girgashites',\n",
       " 'Girgasite',\n",
       " 'Give',\n",
       " 'Go',\n",
       " 'God',\n",
       " 'Gomer',\n",
       " 'Gomorrah',\n",
       " 'Goshen',\n",
       " 'Guni',\n",
       " 'Hadad',\n",
       " 'Hadar',\n",
       " 'Hadoram',\n",
       " 'Hagar',\n",
       " 'Haggi',\n",
       " 'Hai',\n",
       " 'Ham',\n",
       " 'Hamathite',\n",
       " 'Hamor',\n",
       " 'Hamul',\n",
       " 'Hanoch',\n",
       " 'Happy',\n",
       " 'Haran',\n",
       " 'Hast',\n",
       " 'Haste',\n",
       " 'Have',\n",
       " 'Havilah',\n",
       " 'Hazarmaveth',\n",
       " 'Hazezontamar',\n",
       " 'Hazo',\n",
       " 'He',\n",
       " 'Hear',\n",
       " 'Heaven',\n",
       " 'Heber',\n",
       " 'Hebrew',\n",
       " 'Hebrews',\n",
       " 'Hebron',\n",
       " 'Hemam',\n",
       " 'Hemdan',\n",
       " 'Here',\n",
       " 'Hereby',\n",
       " 'Heth',\n",
       " 'Hezron',\n",
       " 'Hiddekel',\n",
       " 'Hinder',\n",
       " 'Hirah',\n",
       " 'His',\n",
       " 'Hitti',\n",
       " 'Hittite',\n",
       " 'Hittites',\n",
       " 'Hivite',\n",
       " 'Hobah',\n",
       " 'Hori',\n",
       " 'Horite',\n",
       " 'Horites',\n",
       " 'How',\n",
       " 'Hul',\n",
       " 'Huppim',\n",
       " 'Husham',\n",
       " 'Hushim',\n",
       " 'Huz',\n",
       " 'I',\n",
       " 'If',\n",
       " 'In',\n",
       " 'Irad',\n",
       " 'Iram',\n",
       " 'Is',\n",
       " 'Isa',\n",
       " 'Isaac',\n",
       " 'Iscah',\n",
       " 'Ishbak',\n",
       " 'Ishmael',\n",
       " 'Ishmeelites',\n",
       " 'Ishuah',\n",
       " 'Isra',\n",
       " 'Israel',\n",
       " 'Issachar',\n",
       " 'Isui',\n",
       " 'It',\n",
       " 'Ithran',\n",
       " 'Jaalam',\n",
       " 'Jabal',\n",
       " 'Jabbok',\n",
       " 'Jac',\n",
       " 'Jachin',\n",
       " 'Jacob',\n",
       " 'Jahleel',\n",
       " 'Jahzeel',\n",
       " 'Jamin',\n",
       " 'Japhe',\n",
       " 'Japheth',\n",
       " 'Jared',\n",
       " 'Javan',\n",
       " 'Jebusite',\n",
       " 'Jebusites',\n",
       " 'Jegarsahadutha',\n",
       " 'Jehovahjireh',\n",
       " 'Jemuel',\n",
       " 'Jerah',\n",
       " 'Jetheth',\n",
       " 'Jetur',\n",
       " 'Jeush',\n",
       " 'Jezer',\n",
       " 'Jidlaph',\n",
       " 'Jimnah',\n",
       " 'Job',\n",
       " 'Jobab',\n",
       " 'Jokshan',\n",
       " 'Joktan',\n",
       " 'Jordan',\n",
       " 'Joseph',\n",
       " 'Jubal',\n",
       " 'Judah',\n",
       " 'Judge',\n",
       " 'Judith',\n",
       " 'Kadesh',\n",
       " 'Kadmonites',\n",
       " 'Karnaim',\n",
       " 'Kedar',\n",
       " 'Kedemah',\n",
       " 'Kemuel',\n",
       " 'Kenaz',\n",
       " 'Kenites',\n",
       " 'Kenizzites',\n",
       " 'Keturah',\n",
       " 'Kiriathaim',\n",
       " 'Kirjatharba',\n",
       " 'Kittim',\n",
       " 'Know',\n",
       " 'Kohath',\n",
       " 'Kor',\n",
       " 'Korah',\n",
       " 'LO',\n",
       " 'LORD',\n",
       " 'Laban',\n",
       " 'Lahairoi',\n",
       " 'Lamech',\n",
       " 'Lasha',\n",
       " 'Lay',\n",
       " 'Leah',\n",
       " 'Lehabim',\n",
       " 'Lest',\n",
       " 'Let',\n",
       " 'Letushim',\n",
       " 'Leummim',\n",
       " 'Levi',\n",
       " 'Lie',\n",
       " 'Lift',\n",
       " 'Lo',\n",
       " 'Look',\n",
       " 'Lot',\n",
       " 'Lotan',\n",
       " 'Lud',\n",
       " 'Ludim',\n",
       " 'Luz',\n",
       " 'Maachah',\n",
       " 'Machir',\n",
       " 'Machpelah',\n",
       " 'Madai',\n",
       " 'Magdiel',\n",
       " 'Magog',\n",
       " 'Mahalaleel',\n",
       " 'Mahalath',\n",
       " 'Mahanaim',\n",
       " 'Make',\n",
       " 'Malchiel',\n",
       " 'Male',\n",
       " 'Mam',\n",
       " 'Mamre',\n",
       " 'Man',\n",
       " 'Manahath',\n",
       " 'Manass',\n",
       " 'Manasseh',\n",
       " 'Mash',\n",
       " 'Masrekah',\n",
       " 'Massa',\n",
       " 'Matred',\n",
       " 'Me',\n",
       " 'Medan',\n",
       " 'Mehetabel',\n",
       " 'Mehujael',\n",
       " 'Melchizedek',\n",
       " 'Merari',\n",
       " 'Mesha',\n",
       " 'Meshech',\n",
       " 'Mesopotamia',\n",
       " 'Methusa',\n",
       " 'Methusael',\n",
       " 'Methuselah',\n",
       " 'Mezahab',\n",
       " 'Mibsam',\n",
       " 'Mibzar',\n",
       " 'Midian',\n",
       " 'Midianites',\n",
       " 'Milcah',\n",
       " 'Mishma',\n",
       " 'Mizpah',\n",
       " 'Mizraim',\n",
       " 'Mizz',\n",
       " 'Moab',\n",
       " 'Moabites',\n",
       " 'Moreh',\n",
       " 'Moreover',\n",
       " 'Moriah',\n",
       " 'Muppim',\n",
       " 'My',\n",
       " 'Naamah',\n",
       " 'Naaman',\n",
       " 'Nahath',\n",
       " 'Nahor',\n",
       " 'Naphish',\n",
       " 'Naphtali',\n",
       " 'Naphtuhim',\n",
       " 'Nay',\n",
       " 'Nebajoth',\n",
       " 'Neither',\n",
       " 'Night',\n",
       " 'Nimrod',\n",
       " 'Nineveh',\n",
       " 'Noah',\n",
       " 'Nod',\n",
       " 'Not',\n",
       " 'Now',\n",
       " 'O',\n",
       " 'Obal',\n",
       " 'Of',\n",
       " 'Oh',\n",
       " 'Ohad',\n",
       " 'Omar',\n",
       " 'On',\n",
       " 'Onam',\n",
       " 'Onan',\n",
       " 'Only',\n",
       " 'Ophir',\n",
       " 'Our',\n",
       " 'Out',\n",
       " 'Padan',\n",
       " 'Padanaram',\n",
       " 'Paran',\n",
       " 'Pass',\n",
       " 'Pathrusim',\n",
       " 'Pau',\n",
       " 'Peace',\n",
       " 'Peleg',\n",
       " 'Peniel',\n",
       " 'Penuel',\n",
       " 'Peradventure',\n",
       " 'Perizzit',\n",
       " 'Perizzite',\n",
       " 'Perizzites',\n",
       " 'Phallu',\n",
       " 'Phara',\n",
       " 'Pharaoh',\n",
       " 'Pharez',\n",
       " 'Phichol',\n",
       " 'Philistim',\n",
       " 'Philistines',\n",
       " 'Phut',\n",
       " 'Phuvah',\n",
       " 'Pildash',\n",
       " 'Pinon',\n",
       " 'Pison',\n",
       " 'Potiphar',\n",
       " 'Potipherah',\n",
       " 'Put',\n",
       " 'Raamah',\n",
       " 'Rachel',\n",
       " 'Rameses',\n",
       " 'Rebek',\n",
       " 'Rebekah',\n",
       " 'Rehoboth',\n",
       " 'Remain',\n",
       " 'Rephaims',\n",
       " 'Resen',\n",
       " 'Return',\n",
       " 'Reu',\n",
       " 'Reub',\n",
       " 'Reuben',\n",
       " 'Reuel',\n",
       " 'Reumah',\n",
       " 'Riphath',\n",
       " 'Rosh',\n",
       " 'Sabtah',\n",
       " 'Sabtech',\n",
       " 'Said',\n",
       " 'Salah',\n",
       " 'Salem',\n",
       " 'Samlah',\n",
       " 'Sarah',\n",
       " 'Sarai',\n",
       " 'Saul',\n",
       " 'Save',\n",
       " 'Say',\n",
       " 'Se',\n",
       " 'Seba',\n",
       " 'See',\n",
       " 'Seeing',\n",
       " 'Seir',\n",
       " 'Sell',\n",
       " 'Send',\n",
       " 'Sephar',\n",
       " 'Serah',\n",
       " 'Sered',\n",
       " 'Serug',\n",
       " 'Set',\n",
       " 'Seth',\n",
       " 'Shalem',\n",
       " 'Shall',\n",
       " 'Shalt',\n",
       " 'Shammah',\n",
       " 'Shaul',\n",
       " 'Shaveh',\n",
       " 'She',\n",
       " 'Sheba',\n",
       " 'Shebah',\n",
       " 'Shechem',\n",
       " 'Shed',\n",
       " 'Shel',\n",
       " 'Shelah',\n",
       " 'Sheleph',\n",
       " 'Shem',\n",
       " 'Shemeber',\n",
       " 'Shepho',\n",
       " 'Shillem',\n",
       " 'Shiloh',\n",
       " 'Shimron',\n",
       " 'Shinab',\n",
       " 'Shinar',\n",
       " 'Shobal',\n",
       " 'Should',\n",
       " 'Shuah',\n",
       " 'Shuni',\n",
       " 'Shur',\n",
       " 'Sichem',\n",
       " 'Siddim',\n",
       " 'Sidon',\n",
       " 'Simeon',\n",
       " 'Sinite',\n",
       " 'Sitnah',\n",
       " 'Slay',\n",
       " 'So',\n",
       " 'Sod',\n",
       " 'Sodom',\n",
       " 'Sojourn',\n",
       " 'Some',\n",
       " 'Spake',\n",
       " 'Speak',\n",
       " 'Spirit',\n",
       " 'Stand',\n",
       " 'Succoth',\n",
       " 'Surely',\n",
       " 'Swear',\n",
       " 'Syrian',\n",
       " 'Take',\n",
       " 'Tamar',\n",
       " 'Tarshish',\n",
       " 'Tebah',\n",
       " 'Tell',\n",
       " 'Tema',\n",
       " 'Teman',\n",
       " 'Temani',\n",
       " 'Terah',\n",
       " 'Thahash',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'Therefore',\n",
       " 'These',\n",
       " 'They',\n",
       " 'Thirty',\n",
       " 'This',\n",
       " 'Thorns',\n",
       " 'Thou',\n",
       " 'Thus',\n",
       " 'Thy',\n",
       " 'Tidal',\n",
       " 'Timna',\n",
       " 'Timnah',\n",
       " 'Timnath',\n",
       " 'Tiras',\n",
       " 'To',\n",
       " 'Togarmah',\n",
       " 'Tola',\n",
       " 'Tubal',\n",
       " 'Tubalcain',\n",
       " 'Twelve',\n",
       " 'Two',\n",
       " 'Unstable',\n",
       " 'Until',\n",
       " 'Unto',\n",
       " 'Up',\n",
       " 'Upon',\n",
       " 'Ur',\n",
       " 'Uz',\n",
       " 'Uzal',\n",
       " 'We',\n",
       " 'What',\n",
       " 'When',\n",
       " 'Whence',\n",
       " 'Where',\n",
       " 'Whereas',\n",
       " 'Wherefore',\n",
       " 'Which',\n",
       " 'While',\n",
       " 'Who',\n",
       " 'Whose',\n",
       " 'Whoso',\n",
       " 'Why',\n",
       " 'Wilt',\n",
       " 'With',\n",
       " 'Woman',\n",
       " 'Ye',\n",
       " 'Yea',\n",
       " 'Yet',\n",
       " 'Zaavan',\n",
       " 'Zaphnathpaaneah',\n",
       " 'Zar',\n",
       " 'Zarah',\n",
       " 'Zeboiim',\n",
       " 'Zeboim',\n",
       " 'Zebul',\n",
       " 'Zebulun',\n",
       " 'Zemarite',\n",
       " 'Zepho',\n",
       " 'Zerah',\n",
       " 'Zibeon',\n",
       " 'Zidon',\n",
       " 'Zillah',\n",
       " 'Zilpah',\n",
       " 'Zimran',\n",
       " 'Ziphion',\n",
       " 'Zo',\n",
       " 'Zoar',\n",
       " 'Zohar',\n",
       " 'Zuzims',\n",
       " 'a',\n",
       " 'abated',\n",
       " 'abide',\n",
       " 'able',\n",
       " 'abode',\n",
       " 'abomination',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absent',\n",
       " 'abundantly',\n",
       " 'accept',\n",
       " 'accepted',\n",
       " 'according',\n",
       " 'acknowledged',\n",
       " 'activity',\n",
       " 'add',\n",
       " 'adder',\n",
       " 'afar',\n",
       " 'afflict',\n",
       " 'affliction',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'aga',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'aileth',\n",
       " 'air',\n",
       " 'al',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'almon',\n",
       " 'alo',\n",
       " 'alone',\n",
       " 'aloud',\n",
       " 'also',\n",
       " 'altar',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'angel',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'anguish',\n",
       " 'anointedst',\n",
       " 'anoth',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'any',\n",
       " 'anything',\n",
       " 'appe',\n",
       " 'appear',\n",
       " 'appeared',\n",
       " 'appease',\n",
       " 'appoint',\n",
       " 'appointed',\n",
       " 'aprons',\n",
       " 'archer',\n",
       " 'archers',\n",
       " 'are',\n",
       " 'arise',\n",
       " 'ark',\n",
       " 'armed',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arose',\n",
       " 'arrayed',\n",
       " 'art',\n",
       " 'artificer',\n",
       " 'as',\n",
       " 'ascending',\n",
       " 'ash',\n",
       " 'ashamed',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asketh',\n",
       " 'ass',\n",
       " 'assembly',\n",
       " 'asses',\n",
       " 'assigned',\n",
       " 'asswaged',\n",
       " 'at',\n",
       " 'attained',\n",
       " 'audience',\n",
       " 'avenged',\n",
       " 'aw',\n",
       " 'awaked',\n",
       " 'away',\n",
       " 'awoke',\n",
       " 'back',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'bade',\n",
       " 'badest',\n",
       " 'badne',\n",
       " 'bak',\n",
       " 'bake',\n",
       " 'bakemeats',\n",
       " 'baker',\n",
       " 'bakers',\n",
       " 'balm',\n",
       " 'bands',\n",
       " 'bank',\n",
       " 'bare',\n",
       " 'barr',\n",
       " 'barren',\n",
       " 'basket',\n",
       " 'baskets',\n",
       " 'battle',\n",
       " 'bdellium',\n",
       " 'be',\n",
       " 'bear',\n",
       " 'beari',\n",
       " 'bearing',\n",
       " 'beast',\n",
       " 'beasts',\n",
       " 'beautiful',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'befall',\n",
       " 'befell',\n",
       " 'before',\n",
       " 'began',\n",
       " 'begat',\n",
       " 'beget',\n",
       " 'begettest',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begotten',\n",
       " 'beguiled',\n",
       " 'beheld',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'being',\n",
       " 'believed',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'beneath',\n",
       " 'bereaved',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'besought',\n",
       " 'best',\n",
       " 'betimes',\n",
       " 'better',\n",
       " 'between',\n",
       " 'betwixt',\n",
       " 'beyond',\n",
       " 'binding',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birthday',\n",
       " 'birthright',\n",
       " 'biteth',\n",
       " 'bitter',\n",
       " 'blame',\n",
       " 'blameless',\n",
       " 'blasted',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blesseth',\n",
       " 'blessi',\n",
       " 'blessing',\n",
       " 'blessings',\n",
       " 'blindness',\n",
       " 'blood',\n",
       " 'blossoms',\n",
       " 'bodies',\n",
       " 'boldly',\n",
       " 'bondman',\n",
       " 'bondmen',\n",
       " 'bondwoman',\n",
       " 'bone',\n",
       " 'bones',\n",
       " 'book',\n",
       " 'booths',\n",
       " 'border',\n",
       " 'borders',\n",
       " 'born',\n",
       " 'bosom',\n",
       " 'both',\n",
       " 'bottle',\n",
       " 'bou',\n",
       " 'boug',\n",
       " 'bough',\n",
       " 'bought',\n",
       " 'bound',\n",
       " 'bow',\n",
       " 'bowed',\n",
       " 'bowels',\n",
       " 'bowing',\n",
       " 'boys',\n",
       " 'bracelets',\n",
       " 'branches',\n",
       " 'brass',\n",
       " 'bre',\n",
       " 'breach',\n",
       " 'bread',\n",
       " 'breadth',\n",
       " 'break',\n",
       " 'breaketh',\n",
       " 'breaking',\n",
       " 'breasts',\n",
       " 'breath',\n",
       " 'breathed',\n",
       " 'breed',\n",
       " 'brethren',\n",
       " 'brick',\n",
       " 'brimstone',\n",
       " 'bring',\n",
       " 'brink',\n",
       " 'broken',\n",
       " 'brook',\n",
       " 'broth',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'bruise',\n",
       " 'budded',\n",
       " 'build',\n",
       " 'builded',\n",
       " 'built',\n",
       " 'bulls',\n",
       " 'bundle',\n",
       " 'bundles',\n",
       " 'burdens',\n",
       " 'buried',\n",
       " 'burn',\n",
       " 'burning',\n",
       " 'burnt',\n",
       " 'bury',\n",
       " 'buryingplace',\n",
       " 'business',\n",
       " 'but',\n",
       " 'butler',\n",
       " 'butlers',\n",
       " 'butlership',\n",
       " 'butter',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'cakes',\n",
       " 'calf',\n",
       " 'call',\n",
       " 'called',\n",
       " 'came',\n",
       " 'camel',\n",
       " 'camels',\n",
       " 'camest',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'canst',\n",
       " 'captain',\n",
       " 'captive',\n",
       " 'captives',\n",
       " 'carcases',\n",
       " 'carried',\n",
       " 'carry',\n",
       " 'cast',\n",
       " 'castles',\n",
       " 'catt',\n",
       " 'cattle',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'cave',\n",
       " 'cease',\n",
       " 'ceased',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chain',\n",
       " 'chamber',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'chariot',\n",
       " 'chariots',\n",
       " 'chesnut',\n",
       " 'chi',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childless',\n",
       " 'childr',\n",
       " 'children',\n",
       " 'chode',\n",
       " 'choice',\n",
       " 'chose',\n",
       " 'circumcis',\n",
       " 'circumcise',\n",
       " 'circumcised',\n",
       " 'citi',\n",
       " 'cities',\n",
       " 'city',\n",
       " 'clave',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'cleave',\n",
       " 'clo',\n",
       " 'closed',\n",
       " 'clothed',\n",
       " 'clothes',\n",
       " 'cloud',\n",
       " 'clusters',\n",
       " 'co',\n",
       " 'coat',\n",
       " 'coats',\n",
       " 'coffin',\n",
       " 'cold',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(text3)) #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(set(text3)) #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By wrapping sorted() around the Python expression set(text3) [1], we obtain a sorted list of vocabulary items, beginning with various punctuation symbols and continuing with words starting with A. All capitalized words precede lowercase words. We discover the size of the vocabulary indirectly, by asking for the number of items in the set, and again we can use len to obtain this number [2]. Although it has 44,764 tokens, this book has only 2,789 distinct words, or \"word types.\" A word type is the form or spelling of the word independently of its specific occurrences in a text — that is, the word considered as a unique item of vocabulary. Our count of 2,789 items will include punctuation symbols, so we will generally call these unique items types instead of word types.\n",
    "\n",
    "Now, let's calculate a measure of the lexical richness of the text. The next example shows us that the number of distinct words is just 6% of the total number of words, or equivalently that each word is used 16 times on average (remember if you're using Python 2, to start with from __future__ import division)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text3)) / len(text3)\n",
    "0.06230453042623537"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's focus on particular words. We can count how often a word occurs in a text, and compute what percentage of the text is taken up by a specific word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3.count(\"smote\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to repeat such calculations on several texts, but it is tedious to keep retyping the formula. Instead, you can come up with your own name for a task, like \"lexical_diversity\" or \"percentage\", and associate it with a block of code. Now you only have to type a short name instead of one or more complete lines of Python code, and you can re-use it as often as you like. The block of code that does a task for us is called a function, and we define a short name for our function with the keyword def. The next example shows how to define two new functions, lexical_diversity() and percentage():\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage(count, total):\n",
    "    return 100 * count / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the definition of lexical_diversity() [1], we specify a parameter named text . This parameter is a \"placeholder\" for the actual text whose lexical diversity we want to compute, and reoccurs in the block of code that will run when the function is used [2]. Similarly, percentage() is defined to take two parameters, named count and total [3].\n",
    "\n",
    "Once Python knows that lexical_diversity() and percentage() are the names for specific blocks of code, we can go ahead and use these functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13477005109975562"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.457806031353621"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage(text4.count('a'), len(text4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap, we use or call a function such as lexical_diversity() by typing its name, followed by an open parenthesis, the name of the text, and then a close parenthesis. These parentheses will show up often; their role is to separate the name of a task — such as lexical_diversity() — from the data that the task is to be performed on — such as text3. The data value that we place in the parentheses when we call a function is an argument to the function.\n",
    "\n",
    "You have already encountered several functions in this chapter, such as len(), set(), and sorted(). By convention, we will always add an empty pair of parentheses after a function name, as in len(), just to make clear that what we are talking about is a function rather than some other kind of Python expression. Functions are an important concept in programming, and we only mention them at the outset to give newcomers a sense of the power and creativity of programming. Don't worry if you find it a bit confusing right now.\n",
    "\n",
    "Later we'll see how to use functions when tabulating data, as in 1.1. Each row of the table will involve the same computation but with different data, and we'll do this repetitive work using a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Start Homework\n",
    "<a id=\"hmw\"></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_urls = {\n",
    "    'THE ADVENTURES OF TOM SAWYER : 4 grade' : 'https://www.gutenberg.org/ebooks/74.txt.utf-8',\n",
    "    'Adventures of Huckleberry Finn: 6 grade': 'https://www.gutenberg.org/ebooks/76.txt.utf-8',\n",
    "    'On War : 12 grade' : 'https://www.gutenberg.org/ebooks/1946.txt.utf-8'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_by_url = {}\n",
    "def get_book_text(url):\n",
    "    if url in books_by_url:\n",
    "        return books_by_url[url]\n",
    "    text = requests.get(url).text\n",
    "    books_by_url[url] = text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_diversity 0.00020622368870178634 | Title: THE ADVENTURES OF TOM SAWYER : 4 grade\n",
      "text_diversity 0.00014341667985440733 | Title: Adventures of Huckleberry Finn: 6 grade\n",
      "text_diversity 0.00014015395372763312 | Title: On War : 12 grade\n"
     ]
    }
   ],
   "source": [
    "def get_diversity_all_texts():\n",
    "    for text_level in text_urls:\n",
    "        url = text_urls[text_level]\n",
    "        text = get_book_text(url)\n",
    "        diversity = lexical_diversity(text)\n",
    "        print('text_diversity {} | Title: {}'.format(diversity, text_level))\n",
    "get_diversity_all_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size 87 | Title: THE ADVENTURES OF TOM SAWYER : 4 grade\n",
      "vocabulary size 87 | Title: Adventures of Huckleberry Finn: 6 grade\n",
      "vocabulary size 91 | Title: On War : 12 grade\n"
     ]
    }
   ],
   "source": [
    "def get_vocabulary_size_all_texts():\n",
    "    for text_level in text_urls:\n",
    "        url = text_urls[text_level]\n",
    "        text = get_book_text(url)\n",
    "        unique_characters = set(text)\n",
    "        vocabulary_size = len(unique_characters)\n",
    "        print('vocabulary size {} | Title: {}'.format(vocabulary_size, text_level))\n",
    "get_vocabulary_size_all_texts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Results\n",
    "\n",
    "### Thoughts on the texts \n",
    "First had some trouble finding books relevant to the a specific grade then locating a copy that on the Gutenburg project. Instead, I thought of books that are likely past their publishers copyright date and have made their way into the public domain. Note that charactorization of the grade level of books is somewhat speculative based on a few google searches. Perhaps 4th and 6th grade is a bit optimistic in today's world. But perhaps once were relevant in a world that existed before internet and cable TV. \n",
    "\n",
    "\n",
    "Having read all three i can attest that the difficulty of the books ascends in order. With a marked jump from penultimate Huck Fin, to final book On War. It is a diffuclt text. The author, Carl von Clauswitz, employs the didatic method to explore his philosophy of War and its role in European/World politics.  On War, is the de-facto book on the Western philosphy of war.  Why countries go to war, How they intend to win, What the objectives of going to war are. These differ somwhat from the Eastern or Chinese philosphy, the African continent, and New World cultures. \n",
    "\n",
    "### Vocabualry.\n",
    "It does astonished me that vocabulary size is only set apart by 4. Not so surprising that Tom Sawyer and Huckleberry Fin are of equal vocab strength. Since both texts come from the lexicon of a singular author. Is this a good measure of what we might consider vocabulary. We are looking at the length of the number of unique words divided by the length of all the words. To me the list seem rather small. That the sum of all words in the text.\n",
    "\n",
    "### Lexical Diversity \n",
    "\n",
    "Is giving a score of how often any one word is repeated in a text. So if a text is long and varies in its use of lexicon (vocabulary) it will have a very low lixcal diversity score. Indicating that the text doesn't repeat the use of words often. Likewise a higher score shows that text doesn't vary much. Something we'd expect from a childrens book. The themes of the book are limited and the scope of narrative as well. \n",
    "\n",
    "I think what often sets the two books apart in grade level is not the complexity of the text but the social complexity that which the text deals with. Huck Fin deals in large part with slavery.  Published just 20 years after its abolition in the United States. It is often forgot that one intention of Mark Tawain is to mock the instution. Shed light upon the hypcrosiy by having Huckleberry Fin enslaved by his father escape and go on an adventure with Jim an escaped black slave. And also use the two as a literary device to show how the two worlds of white and black american are intertwined. In a similar vain i've seen the similar misinterpreations of texts like Frankenstien. Where people wonder out loud if Frankenstien's monster wasn't really a monster afterall just misunderstood. When in fact that is in the story. \n",
    "\n",
    "Taken this into account one can see that vocabulary is a crude approximation of text difficulty. Certaintly, it has its place. The line gets blurred as we step away children's books. Whose purpose is to develop literacy in developing minds. And into the larger body of texts that comprise the cannon of cultural literature. The text diversity and vocabulary are one abstraction that can inform. But then again all models are wrong some are useful.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
