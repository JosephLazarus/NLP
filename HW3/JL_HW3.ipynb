{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04df027a",
   "metadata": {},
   "source": [
    "1.\tCompare your given name with your nickname (if you don’t have a nickname, invent one for this assignment) by answering the following questions:\n",
    "\n",
    "    a.\tWhat is the edit distance between your nickname and your given name?\n",
    "\n",
    "    b.\tWhat is the percentage string match between your nickname and your given name?\n",
    "\n",
    "Show your work for both calculations.\n",
    "\n",
    "2.\tFind a friend (or family member or classmate) who you know has read a certain book. Without your friend knowing, copy the first two sentences of that book. Now rewrite the words from those sentences, excluding stop words. Now tell your friend to guess which book the words are from by reading them just that list of words. Did you friend correctly guess the book on the first try? What did he or she guess? Explain why you think you friend either was or was not able to guess the book from hearing the list of words. \n",
    "\n",
    "\n",
    "3.\tRun one of the stemmers available in Python. Run the same two sentences from question 2 above through the stemmer and show the results. How many of the outputted stems are valid morphological roots of the corresponding words? Express this answer as a percentage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd49699c",
   "metadata": {},
   "source": [
    "| Start | Delete | insert | Finish| Total Distance |\n",
    "| --- | --- | --- | ---| ---|\n",
    "| Joe | 0 | y (1) | Joey (1) | |\n",
    "| Lazarus| Lazarus (6)| Fettuccine (10)| Fettuccine (16) |\n",
    "| -| -|- | | 17|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51acc179",
   "metadata": {},
   "source": [
    "**Percentage Mataching\n",
    "3 / 14  = 21.4%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a4096f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce50fbd3",
   "metadata": {},
   "source": [
    "From David Sedaris Me talk pretty one day:\n",
    "\n",
    "At the age of forty-one, I am returning to school and have to think of myself as\n",
    "what my French textbook calls “a true debutant.” After paying my tuition, I was issued\n",
    "a student ID, which allows me a discounted entry fee at movie theaters, puppet shows,\n",
    "and Festyland, a far-flung amusement park that advertises with billboards picturing a\n",
    "cartoon stegosaurus sitting in a canoe and eating what appears to be a ham sandwich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a58d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "David = 'At the age of forty-one, I am returning to school and have to think of myself as what my French textbook calls “a true debutant.” After paying my tuition, I was issued a student ID, which allows me a discounted entry fee at movie theaters, puppet shows, and Festyland, a far-flung amusement park that advertises with billboards picturing a cartoon stegosaurus sitting in a canoe and eating what appears to be a ham sandwich.'\n",
    "David = word_tokenize(David)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25b2bc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53985a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(word_list):\n",
    "        processed_word_list = []\n",
    "        for word in word_list:\n",
    "            word = word.lower() # in case they arenet all lower cased\n",
    "            if word not in stopwords.words(\"english\"):\n",
    "                processed_word_list.append(word)\n",
    "        return processed_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15c11f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'forty-one',\n",
       " ',',\n",
       " 'returning',\n",
       " 'school',\n",
       " 'think',\n",
       " 'french',\n",
       " 'textbook',\n",
       " 'calls',\n",
       " '“',\n",
       " 'true',\n",
       " 'debutant.',\n",
       " '”',\n",
       " 'paying',\n",
       " 'tuition',\n",
       " ',',\n",
       " 'issued',\n",
       " 'student',\n",
       " 'id',\n",
       " ',',\n",
       " 'allows',\n",
       " 'discounted',\n",
       " 'entry',\n",
       " 'fee',\n",
       " 'movie',\n",
       " 'theaters',\n",
       " ',',\n",
       " 'puppet',\n",
       " 'shows',\n",
       " ',',\n",
       " 'festyland',\n",
       " ',',\n",
       " 'far-flung',\n",
       " 'amusement',\n",
       " 'park',\n",
       " 'advertises',\n",
       " 'billboards',\n",
       " 'picturing',\n",
       " 'cartoon',\n",
       " 'stegosaurus',\n",
       " 'sitting',\n",
       " 'canoe',\n",
       " 'eating',\n",
       " 'appears',\n",
       " 'ham',\n",
       " 'sandwich',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(David)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941beb5",
   "metadata": {},
   "source": [
    "My girlfriend didn't correctly guess the book. I think one she really wasn't into the game. Two she wasn't expected to get a rather disjointed read of words. That is to say without the stop words it didn't flow. The stop words kinda of act like glue that binds thoughts together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ed19c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05050995",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc762a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "David = 'At the age of forty-one, I am returning to school and have to think of myself as what my French textbook calls “a true debutant.” After paying my tuition, I was issued a student ID, which allows me a discounted entry fee at movie theaters, puppet shows, and Festyland, a far-flung amusement park that advertises with billboards picturing a cartoon stegosaurus sitting in a canoe and eating what appears to be a ham sandwich.'\n",
    "David = word_tokenize(David)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b25823a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at\n",
      "the\n",
      "age\n",
      "of\n",
      "forty-on\n",
      ",\n",
      "i\n",
      "am\n",
      "return\n",
      "to\n",
      "school\n",
      "and\n",
      "have\n",
      "to\n",
      "think\n",
      "of\n",
      "myself\n",
      "as\n",
      "what\n",
      "my\n",
      "french\n",
      "textbook\n",
      "call\n",
      "“\n",
      "a\n",
      "true\n",
      "debutant.\n",
      "”\n",
      "after\n",
      "pay\n",
      "my\n",
      "tuition\n",
      ",\n",
      "i\n",
      "wa\n",
      "issu\n",
      "a\n",
      "student\n",
      "id\n",
      ",\n",
      "which\n",
      "allow\n",
      "me\n",
      "a\n",
      "discount\n",
      "entri\n",
      "fee\n",
      "at\n",
      "movi\n",
      "theater\n",
      ",\n",
      "puppet\n",
      "show\n",
      ",\n",
      "and\n",
      "festyland\n",
      ",\n",
      "a\n",
      "far-flung\n",
      "amus\n",
      "park\n",
      "that\n",
      "advertis\n",
      "with\n",
      "billboard\n",
      "pictur\n",
      "a\n",
      "cartoon\n",
      "stegosauru\n",
      "sit\n",
      "in\n",
      "a\n",
      "cano\n",
      "and\n",
      "eat\n",
      "what\n",
      "appear\n",
      "to\n",
      "be\n",
      "a\n",
      "ham\n",
      "sandwich\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for w in David:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7c19c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemma(text):\n",
    "    stem_words = [ps.stem(w) for w in David]\n",
    "    return stem_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9e09f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = stemma(David)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f99a7a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('student.n.01'), Synset('scholar.n.01')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('student')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19647ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wn.synsets('student')) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82c42923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at', 'age', 'i', 'am', 'return', 'school', 'have', 'think', 'as', 'french', 'textbook', 'call', 'a', 'true', 'after', 'pay', 'tuition', 'i', 'wa', 'a', 'student', 'id', 'allow', 'me', 'a', 'discount', 'fee', 'at', 'theater', 'puppet', 'show', 'a', 'far-flung', 'park', 'billboard', 'a', 'cartoon', 'sit', 'in', 'a', 'eat', 'appear', 'be', 'a', 'ham', 'sandwich']\n",
      "\n",
      "['the', 'of', 'forty-on', ',', 'to', 'and', 'to', 'of', 'myself', 'what', 'my', '“', 'debutant.', '”', 'my', ',', 'issu', ',', 'which', 'entri', 'movi', ',', ',', 'and', 'festyland', ',', 'amus', 'that', 'advertis', 'with', 'pictur', 'stegosauru', 'cano', 'and', 'what', 'to', '.']\n"
     ]
    }
   ],
   "source": [
    "true_words = []\n",
    "false_words =[]\n",
    "\n",
    "for w in stemmed_words:\n",
    "    if wn.synsets(w):\n",
    "        true_words.append(w)\n",
    "    \n",
    "    else:\n",
    "        false_words.append(w)\n",
    "print(true_words)\n",
    "print()\n",
    "print(false_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "56f0c352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5542168674698795"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_words) / len(stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17a80ab",
   "metadata": {},
   "source": [
    "Using Porter stemmer and some verbose code I get a rough percentage of valid or true words when i compare them against wordNet. \n",
    "\n",
    "However, if we look at the false words, I think some of them are valid. Part of that is the process of tokenization and maybe my code could be better. But I count only 8 words in the false_words that are in fact not valid words. The length of the two sentences is 46. I tink closer to 82%. (46-8) / 46\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
